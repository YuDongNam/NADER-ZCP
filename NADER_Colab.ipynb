{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# NADER - Neural Architecture Design via Multi-Agent Collaboration\n",
                "\n",
                "## Google Colab Execution Notebook\n",
                "\n",
                "### ì‚¬ìš©ë²•:\n",
                "1. GPU ëŸ°íƒ€ì„ ì„ íƒ: `ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > GPU`\n",
                "2. Google Driveì— NADER í”„ë¡œì íŠ¸ ì—…ë¡œë“œ\n",
                "3. ì•„ë˜ ì…€ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 1: Google Drive ë§ˆìš´íŠ¸"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 60)\n",
                "print(\"Step 1: Mounting Google Drive...\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 2: í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"Step 2: Setting up project paths...\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# ============================================\n",
                "# ì—¬ê¸°ì„œ í”„ë¡œì íŠ¸ ê²½ë¡œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”!\n",
                "# ============================================\n",
                "PROJECT_PATH = \"/content/drive/MyDrive/NADER\"  # Google Drive ë‚´ NADER í´ë” ê²½ë¡œ\n",
                "# ============================================\n",
                "\n",
                "# ê²½ë¡œ í™•ì¸ ë° ì´ë™\n",
                "if not os.path.exists(PROJECT_PATH):\n",
                "    raise FileNotFoundError(f\"í”„ë¡œì íŠ¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {PROJECT_PATH}\")\n",
                "\n",
                "os.chdir(PROJECT_PATH)\n",
                "print(f\"Working directory: {os.getcwd()}\")\n",
                "\n",
                "# Python path ì¶”ê°€\n",
                "sys.path.insert(0, PROJECT_PATH)\n",
                "sys.path.insert(0, os.path.join(PROJECT_PATH, 'nader'))\n",
                "sys.path.insert(0, os.path.join(PROJECT_PATH, 'zero-cost-nas'))\n",
                "\n",
                "print(f\"Python path updated!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 3: ì˜ì¡´ì„± ì„¤ì¹˜\n",
                "\n",
                "âš ï¸ **ì„¤ì¹˜ í›„ ëŸ°íƒ€ì„ ì¬ì‹œì‘ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"Step 3: Installing dependencies...\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# requirements.txtë¡œ ì „ì²´ ì˜ì¡´ì„± ì„¤ì¹˜\n",
                "!pip install -r requirements.txt\n",
                "\n",
                "# ì¶”ê°€ langchain íŒ¨í‚¤ì§€ ì„¤ì¹˜ (í•„ìš”ì‹œ)\n",
                "!pip install -q langchain-openai langchain-classic langchain-chroma"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 4: GPU í™•ì¸"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"Step 4: Checking GPU...\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "import torch\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"CUDA version: {torch.version.cuda}\")\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                "else:\n",
                "    print(\"âš ï¸ WARNING: GPU not available!\")\n",
                "    print(\"   ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > GPU ì„ íƒ\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 5: Config ì„¤ì • (GPU í™œì„±í™”)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"Step 5: Configuring NADER for GPU...\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "config_path = os.path.join(PROJECT_PATH, 'nader/train_utils/config.py')\n",
                "print(f\"Config path: {config_path}\")\n",
                "\n",
                "# config.py íŒŒì¼ ì½ê¸°\n",
                "with open(config_path, 'r') as f:\n",
                "    config_content = f.read()\n",
                "\n",
                "# USE_GPU = True (GPU ì‚¬ìš©)\n",
                "if '_C.USE_GPU = False' in config_content:\n",
                "    config_content = config_content.replace('_C.USE_GPU = False', '_C.USE_GPU = True')\n",
                "    print(\"âœ“ USE_GPU: False -> True\")\n",
                "else:\n",
                "    print(\"âœ“ USE_GPU: already True\")\n",
                "\n",
                "# NUM_WORKERS = 4 (Colabìš©)\n",
                "if '_C.DATA.NUM_WORKERS = 0' in config_content:\n",
                "    config_content = config_content.replace('_C.DATA.NUM_WORKERS = 0', '_C.DATA.NUM_WORKERS = 4')\n",
                "    print(\"âœ“ NUM_WORKERS: 0 -> 4\")\n",
                "else:\n",
                "    print(\"âœ“ NUM_WORKERS: already configured\")\n",
                "\n",
                "# íŒŒì¼ ì €ì¥\n",
                "with open(config_path, 'w') as f:\n",
                "    f.write(config_content)\n",
                "\n",
                "print(\"\\nâœ“ Config ì„¤ì • ì™„ë£Œ!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 6: OpenAI API Key ì„¤ì •\n",
                "\n",
                "âš ï¸ **ë°˜ë“œì‹œ ì‹¤ì œ API Keyë¡œ ë³€ê²½í•˜ì„¸ìš”!**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"Step 6: Setting OpenAI API Key...\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "import os\n",
                "\n",
                "# ============================================\n",
                "# âš ï¸ ì—¬ê¸°ì— OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”!\n",
                "# ============================================\n",
                "OPENAI_API_KEY = \"your_openai_api_key_here\"  # <-- ìˆ˜ì • í•„ìš”!\n",
                "LLM_MODEL_NAME = \"gpt-4o\"  # ì¶”ì²œ: gpt-4o (ë¹ ë¥´ê³  ì •í™•í•¨)\n",
                "# ============================================\n",
                "\n",
                "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
                "os.environ[\"LLM_MODEL_NAME\"] = LLM_MODEL_NAME\n",
                "\n",
                "if OPENAI_API_KEY == \"your_openai_api_key_here\":\n",
                "    print(\"âš ï¸  WARNING: OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
                "    print(\"   ìœ„ì˜ OPENAI_API_KEYë¥¼ ì‹¤ì œ í‚¤ë¡œ ë³€ê²½í•˜ì„¸ìš”.\")\n",
                "else:\n",
                "    print(f\"âœ“ OpenAI API Key ì„¤ì • ì™„ë£Œ\")\n",
                "    print(f\"âœ“ LLM Model: {LLM_MODEL_NAME}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 7: ì‹¤í–‰ íŒŒë¼ë¯¸í„° ì„¤ì •"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"Step 7: NADER Execution Parameters...\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# ============================================\n",
                "# ì‹¤í–‰ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
                "# ============================================\n",
                "PARAMS = {\n",
                "    \"max_iter\": 3,          # Iteration íšŸìˆ˜\n",
                "    \"dataset\": \"cifar10\",   # cifar10, cifar100, imagenet16-120\n",
                "    \"gen_num\": 50,          # ìƒì„±í•  ì•„í‚¤í…ì²˜ ìˆ˜\n",
                "    \"proxy\": \"synflow\",     # synflow, snip, grasp, fisher, grad_norm, jacob_cov\n",
                "    \"top_k\": 5,             # Top-K ì„ ì •\n",
                "    \"epochs\": 200,          # í•™ìŠµ ì—í¬í¬ ìˆ˜\n",
                "    \"width\": 5,             # DFS width\n",
                "    \"seed\": 777,            # Random seed\n",
                "    \"cluster\": \"colab\",     # í´ëŸ¬ìŠ¤í„° ì„¤ì •\n",
                "    \n",
                "    # Resume ì˜µì…˜ (ì¤‘ë‹¨ í›„ ì¬ê°œì‹œ ì‚¬ìš©)\n",
                "    \"resume\": False,        # Trueë¡œ ë³€ê²½í•˜ë©´ ì´ì „ ìƒíƒœì—ì„œ ì¬ê°œ\n",
                "    \"resume_log_dir\": None, # íŠ¹ì • í´ë”ì—ì„œ ì¬ê°œì‹œ ê²½ë¡œ ì§€ì •\n",
                "}\n",
                "\n",
                "print(\"ì‹¤í–‰ íŒŒë¼ë¯¸í„°:\")\n",
                "for k, v in PARAMS.items():\n",
                "    print(f\"  {k}: {v}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 7.5: Resume ìƒíƒœ ìƒì„± (ì„ íƒì‚¬í•­)\n",
                "\n",
                "âš ï¸ **ì¤‘ë‹¨ëœ ì‹¤í—˜ì„ ì¬ê°œí•  ë•Œë§Œ ì´ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”!**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# ì¤‘ë‹¨ëœ ì‹¤í—˜ì„ ì¬ê°œí•˜ë ¤ë©´ ì•„ë˜ ê°’ì„ Trueë¡œ ë³€ê²½!\n",
                "# ============================================\n",
                "GENERATE_RESUME_STATE = False\n",
                "# ============================================\n",
                "\n",
                "if GENERATE_RESUME_STATE:\n",
                "    import json\n",
                "    import glob\n",
                "    \n",
                "    print(\"\\n\" + \"=\" * 60)\n",
                "    print(\"Resume ìƒíƒœ íŒŒì¼ ìƒì„± ì¤‘...\")\n",
                "    print(\"=\" * 60)\n",
                "    \n",
                "    # 1. ë¡œê·¸ ë””ë ‰í† ë¦¬ ìë™ ì°¾ê¸°\n",
                "    log_base = f\"logs/nas-bench-201/{PARAMS['dataset']}\"\n",
                "    log_dirs = glob.glob(f\"{log_base}/*seed{PARAMS['seed']}*\")\n",
                "    \n",
                "    if log_dirs:\n",
                "        LOG_DIR = sorted(log_dirs)[-1]\n",
                "        print(f\"âœ“ ë¡œê·¸ ë””ë ‰í† ë¦¬ ë°œê²¬: {LOG_DIR}\")\n",
                "    else:\n",
                "        LOG_DIR = \"\"\n",
                "        print(\"âš ï¸ ë¡œê·¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ì— ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”:\")\n",
                "        # LOG_DIR = \"logs/nas-bench-201/cifar10/your_folder_name\"  # ì§ì ‘ ì…ë ¥\n",
                "    \n",
                "    if LOG_DIR:\n",
                "        # 2. block_txtì—ì„œ generated_archs ìƒì„±\n",
                "        block_txt_dir = os.path.join(LOG_DIR, 'block_txt')\n",
                "        if os.path.exists(block_txt_dir):\n",
                "            generated_archs = []\n",
                "            for filename in os.listdir(block_txt_dir):\n",
                "                if filename.endswith('.txt') and 'resnet_basic.txt' != filename:\n",
                "                    with open(os.path.join(block_txt_dir, filename), 'r') as f:\n",
                "                        arch_content = f.read()\n",
                "                    model_name = filename.replace('.txt', '')\n",
                "                    generated_archs.append({\n",
                "                        \"arch\": arch_content,\n",
                "                        \"model_name\": model_name\n",
                "                    })\n",
                "            \n",
                "            archs_path = os.path.join(LOG_DIR, 'generated_archs_iter1.json')\n",
                "            with open(archs_path, 'w') as f:\n",
                "                json.dump(generated_archs, f, indent=2)\n",
                "            print(f\"âœ“ generated_archs_iter1.json ìƒì„±! ({len(generated_archs)} architectures)\")\n",
                "        \n",
                "        # 3. resume_state.json ìƒì„±\n",
                "        RESUME_ITER = 1   # ë©ˆì¶˜ iteration ë²ˆí˜¸\n",
                "        RESUME_STEP = 2   # ì¬ê°œí•  step (2=Proxy í‰ê°€ë¶€í„°, 3=í•™ìŠµë¶€í„°)\n",
                "        \n",
                "        resume_state = {\n",
                "            \"current_iter\": RESUME_ITER,\n",
                "            \"current_step\": RESUME_STEP,\n",
                "            \"overall_best_test_acc\": -1,\n",
                "            \"overall_best_val_acc\": -1,\n",
                "            \"overall_best_model\": None\n",
                "        }\n",
                "        \n",
                "        state_path = os.path.join(LOG_DIR, 'resume_state.json')\n",
                "        with open(state_path, 'w') as f:\n",
                "            json.dump(resume_state, f, indent=2)\n",
                "        print(f\"âœ“ resume_state.json ìƒì„±! (iter={RESUME_ITER}, step={RESUME_STEP})\")\n",
                "        \n",
                "        # PARAMS ì—…ë°ì´íŠ¸\n",
                "        PARAMS[\"resume\"] = True\n",
                "        PARAMS[\"resume_log_dir\"] = LOG_DIR\n",
                "        print(f\"\\nâœ“ Resume ì¤€ë¹„ ì™„ë£Œ!\")\n",
                "        print(f\"  Step 8ì„ ì‹¤í–‰í•˜ë©´ iter {RESUME_ITER}ì˜ step {RESUME_STEP}ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
                "else:\n",
                "    print(\"Resume ëª¨ë“œê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
                "    print(\"ì¤‘ë‹¨ëœ ì‹¤í—˜ì„ ì¬ê°œí•˜ë ¤ë©´ GENERATE_RESUME_STATE = Trueë¡œ ë³€ê²½í•˜ì„¸ìš”.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 8: NADER ì‹¤í–‰\n",
                "\n",
                "ğŸš€ **ë©”ì¸ ì‹¤í–‰ ì…€ì…ë‹ˆë‹¤!**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"Step 8: Running NADER...\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# Resume ì˜µì…˜ ì¶”ê°€\n",
                "resume_args = \"\"\n",
                "if PARAMS.get(\"resume\", False):\n",
                "    resume_args = \" --resume\"\n",
                "    if PARAMS.get(\"resume_log_dir\"):\n",
                "        resume_args += f' --resume-log-dir \"{PARAMS[\"resume_log_dir\"]}\"'\n",
                "    print(f\"[Resume Mode] ì´ì „ ìƒíƒœì—ì„œ ì¬ê°œí•©ë‹ˆë‹¤.\")\n",
                "\n",
                "# ëª…ë ¹ì–´ ìƒì„±\n",
                "cmd = f\"\"\"python nader/nader-nas-bench-201-full.py \\\n",
                "    --max-iter {PARAMS['max_iter']} \\\n",
                "    --dataset {PARAMS['dataset']} \\\n",
                "    --gen-num {PARAMS['gen_num']} \\\n",
                "    --proxy {PARAMS['proxy']} \\\n",
                "    --top-k {PARAMS['top_k']} \\\n",
                "    --epochs {PARAMS['epochs']} \\\n",
                "    --width {PARAMS['width']} \\\n",
                "    --seed {PARAMS['seed']} \\\n",
                "    --cluster {PARAMS['cluster']}{resume_args}\"\"\"\n",
                "\n",
                "print(f\"\\nì‹¤í–‰ ëª…ë ¹:\\n{cmd}\\n\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# ì‹¤í–‰!\n",
                "!{cmd}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 9: ê²°ê³¼ í™•ì¸"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"Step 9: Checking Results...\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "import os\n",
                "import json\n",
                "\n",
                "# ê²°ê³¼ ê²½ë¡œ\n",
                "result_base = f\"logs/nas-bench-201/{PARAMS['dataset']}\"\n",
                "\n",
                "# iteration_results.jsonl íŒŒì¼ ì°¾ê¸°\n",
                "found_results = False\n",
                "for root, dirs, files in os.walk(result_base):\n",
                "    for f in files:\n",
                "        if f == 'iteration_results.jsonl':\n",
                "            result_path = os.path.join(root, f)\n",
                "            print(f\"\\nê²°ê³¼ íŒŒì¼ ë°œê²¬: {result_path}\")\n",
                "            found_results = True\n",
                "            \n",
                "            with open(result_path, 'r') as file:\n",
                "                for line in file:\n",
                "                    result = json.loads(line)\n",
                "                    print(f\"\\n--- Iteration {result['iteration']} ---\")\n",
                "                    print(f\"  Best Model: {result['best_model_this_iter']['model_name']}\")\n",
                "                    print(f\"  Test Acc: {result['best_model_this_iter']['test_acc']:.2f}%\")\n",
                "                    print(f\"  Total Time: {result['total_time_sec']:.2f}s\")\n",
                "\n",
                "if not found_results:\n",
                "    print(\"ì•„ì§ ì™„ë£Œëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"ê²°ê³¼ í™•ì¸ ì™„ë£Œ!\")\n",
                "print(\"=\" * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 10: ê²°ê³¼ë¥¼ Google Driveì— ì €ì¥\n",
                "\n",
                "ğŸ“¦ **logs, output í´ë”ë¥¼ Google Driveì— ë°±ì—…í•©ë‹ˆë‹¤.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"Step 10: Saving results to Google Drive...\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "import shutil\n",
                "import os\n",
                "from datetime import datetime\n",
                "\n",
                "# ============================================\n",
                "# ì €ì¥ ê²½ë¡œ ì„¤ì •\n",
                "# ============================================\n",
                "GDRIVE_SAVE_PATH = \"/content/drive/MyDrive/NADER_Results\"  # Google Drive ì €ì¥ ê²½ë¡œ\n",
                "# ============================================\n",
                "\n",
                "# íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„± (í´ë”ëª… ì¶©ëŒ ë°©ì§€)\n",
                "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                "save_folder = f\"{GDRIVE_SAVE_PATH}/{PARAMS['dataset']}_{PARAMS['seed']}_{timestamp}\"\n",
                "\n",
                "# ì €ì¥ í´ë” ìƒì„±\n",
                "os.makedirs(save_folder, exist_ok=True)\n",
                "\n",
                "# 1. logs í´ë” ë³µì‚¬\n",
                "logs_src = os.path.join(PROJECT_PATH, \"logs\")\n",
                "logs_dst = os.path.join(save_folder, \"logs\")\n",
                "\n",
                "if os.path.exists(logs_src):\n",
                "    print(f\"\\nğŸ“ Copying logs folder...\")\n",
                "    shutil.copytree(logs_src, logs_dst)\n",
                "    print(f\"   âœ“ logs -> {logs_dst}\")\n",
                "else:\n",
                "    print(f\"   âš ï¸ logs folder not found\")\n",
                "\n",
                "# 2. output í´ë” ë³µì‚¬\n",
                "output_src = os.path.join(PROJECT_PATH, \"output\")\n",
                "output_dst = os.path.join(save_folder, \"output\")\n",
                "\n",
                "if os.path.exists(output_src):\n",
                "    print(f\"\\nğŸ“ Copying output folder...\")\n",
                "    shutil.copytree(output_src, output_dst)\n",
                "    print(f\"   âœ“ output -> {output_dst}\")\n",
                "else:\n",
                "    print(f\"   âš ï¸ output folder not found\")\n",
                "\n",
                "print(f\"\\n\" + \"=\" * 60)\n",
                "print(f\"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ!\")\n",
                "print(f\"ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {save_folder}\")\n",
                "print(\"=\" * 60)"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}